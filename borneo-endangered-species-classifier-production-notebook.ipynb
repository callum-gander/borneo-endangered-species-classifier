{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borneo Endangered Species Classifier\n",
    "\n",
    "This is the project I did for the fast.ai lesson 2 homework. This classifer will correct classify 3 critically endangered mammals native to the Borneo Rainforest: the Borneo Orangutan, the Eastern Sumatran Rhinoceros, and the Borneo pygmy elephant. Go ahead and give it a try! If you're interested about my process and the current limitations of this model, see below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from fastai2.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [Path('export.pkl')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path()\n",
    "path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner(path/'export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('borneo orangutan',\n",
       " tensor(0),\n",
       " tensor([9.9999e-01, 1.1462e-06, 4.6091e-06, 9.3500e-08]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_inf.predict('images/orangutan.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) ['borneo orangutan','borneo pygmy elephant','borneo rainforest','eastern sumatran rhinoceros']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_inf.dls.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a85336cdbe4b8db43464278780f277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "btn_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-82db33b3197c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtn_upload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img = PILImage.create(btn_upload.data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de9caffb2d24642ae5d2ff551f09ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_pl = widgets.Output()\n",
    "out_pl.clear_output()\n",
    "with out_pl: display(img.to_thumb(128,128))\n",
    "out_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred,pred_idx,probs = learn_inf.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000ec7ad54ff411ba40eda419bccbcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Prediction: eastern sumatran rhinoceros; Probability: 0.9996')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lbl_pred = widgets.Label()\n",
    "lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
    "lbl_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f2726bdf764f359c23e9cd701ae132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Classify', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "btn_run = widgets.Button(description='Classify')\n",
    "btn_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(img.to_thumb(128,128))\n",
    "    pred,pred_idx,probs = learn_inf.predict(img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
    "\n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Putting back btn_upload to a widget for next cell\n",
    "btn_upload = widgets.FileUpload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc53b6d62544ec78417ff92e2f4faf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Upload a photo to see if it contains an endangered animal on Borneo!'), FileUpload…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([widgets.Label('Upload a photo to see if it contains an endangered animal on Borneo!'), \n",
    "      btn_upload, btn_run, out_pl, lbl_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Your Notebook into a Real App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install voila\n",
    "!jupyter serverextension enable voila —sys-prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data consists of the three types of endangered large mammals we want to classify: the Borneo Orangutan, the Eastern Sumatran Rhinoceros, and the Borneo Pygmy Elephant. The fourth class, the borneo rainforest, is there as a sort of control. If this was used in production, presumably in photos that do not contain these animals a camera would be seeing the borneo rainforest. This is more a proof of concept than a production ready applications, the problems with the data will be discussed below.\n",
    "\n",
    "Note: an \"other animals\" category may be useful for preventing misclassification of other large mammals that live in the borneo rainforest as any of the endangered species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Further Research\n",
    "This model works exceptionally well (>99.9% accuracy), however, there are still obstacles to practical application and  additions/alternatives that may be better suited to this task. \n",
    "\n",
    "### Data issues and Further Research\n",
    "The data itself has some issues. All images were taken from Bing Image Search and as such aren't representive of the low resolution, differently lit photos that you would get from say placing raspberry pi's with cameras around the jungle. Most photos are stylised photos taken by professional photographers and many don't show the animals as they would appear in the jungle. Another issue is that they don't include many, if any, night time photos of the animals, which would mean that it would not identify the animals at night, however, this could be compensated by either building a dataset of these types of images or relying on other models, such as audio or heat based models at night. \n",
    "\n",
    "There are also problems related to the class composition of the dataset. Firstly, while it contains a control class of photos of the borneo rainforest, as mentioned above, that are likely unrepresentative of photos the cameras would take. Beyond this, a further control would be needed of \"other animals\", which would provide a class of many other animals in the borneo rainforest so that the model would not misclassify them as one of the three animals. Of course, you could add all of these animals as separate classes, but this would make the model more complex and likely distract from its ability to correctly identify those mammals that are most at risk. Secondly, further data point might be wise to add, that of poachers/loggers. As one of the main threats to these animals is both hunting and destruction of their environment by loggers, using the model to also track them would likely be incredibly helpful in keeping track of and alerting authorities of their presence\n",
    "\n",
    "Beyond these there are a number of additions/substitutions to the image based model that could augment it overall as well as provide alternatives to it in situations where it may not perform well. \n",
    "- Video-based model: adding a video based model so that when the image classifer detects one of the endangered animals it could switch to a live video feed. Alternatively, you could just stick to the image based model, that increases the number of images taken once an endangered animal is detected and sends notifications to local conservationists so they can track their location and behaviour or tag untagged animals\n",
    "- Audio-based model: adding a audio based model to complement or replace image based model. Build a dataset of the sounds of each animal (calls, movement sounds, etc.), convert the audio into images, use a CNN to classify them or use a RNN to just directly classify the sound. I'm not sure about the power costs of this\n",
    "- Heat-based model: adding a heat based model that uses an infrared camera to classify animals. Would like be helpful during night, however, there are many issues I'm unsure of\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
